{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower_Class_Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6HXPlEQ2OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "from sklearn.decomposition import *\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm8KIYIpQ8ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "61c82458-7151-4aad-81e1-f805f7218da1"
      },
      "source": [
        "!pip install prince"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prince\n",
            "  Downloading https://files.pythonhosted.org/packages/51/f4/8de7003b86351a0e32e29ca2bbbbbf58e311b09f9286e83e638d437aee6d/prince-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from prince) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from prince) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from prince) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.6/dist-packages (from prince) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.6/dist-packages (from prince) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.2->prince) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.3->prince) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->prince) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=3.0.2->prince) (1.15.0)\n",
            "Installing collected packages: prince\n",
            "Successfully installed prince-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8K3RftlQ8he",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "84859488-eae0-4698-b351-a05bb9da7fe5"
      },
      "source": [
        "!pip install catboost==0.23.2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost==0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (1.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost==0.23.2) (1.18.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost==0.23.2) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost==0.23.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost==0.23.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.23.2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.23.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.23.2) (1.2.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QD_nBAkQ8j-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import prince\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz-YL4NxQ8mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_groupby(df,primary_keys,dictionary_ops,renaming_dict):\n",
        "    '''\n",
        "        primary_keys is a list of primary keys.\n",
        "        dictionary_ops is the dictionay having the operations to be performed (example :- {'location_number':'count'})\n",
        "        renaming_dict is the column to be renamed after joining and resetting index\n",
        "    '''\n",
        "    return df.groupby(primary_keys).agg(dictionary_ops).reset_index().rename(columns=renaming_dict)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NozhpLvzQ8rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_left_join(df1,df2,primary_key):\n",
        "    '''\n",
        "        df1 :- First dataframe\n",
        "        df2 :- Second Dataframe\n",
        "        primary_key :- The list of primary keys on which one needs to left join\n",
        "    '''\n",
        "    return df1.merge(df2,how='left',on=primary_key)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9JDXp-vQ8u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def updated_df(df,primary_key,operation,columns):\n",
        "    for cols in columns:\n",
        "        print('Aggregate ',operation ,' on column- ',cols)\n",
        "        df       = data_left_join(df,\n",
        "                                   my_groupby(df,\n",
        "                                              [primary_key],\n",
        "                                              {cols:operation},\n",
        "                                              {cols:primary_key+'_'+operation+'_'+cols}),\n",
        "                                   primary_key)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkRwKS2RQ80P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('Train.csv')\n",
        "test_data = pd.read_csv('Test.csv')\n",
        "train_y = train_data.Class.values\n",
        "train_data = train_data.drop(['Class'],axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZWnX8xBQ833",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concat_df                          = pd.concat((train_data,test_data),axis=0)\n",
        "cat_cols                           = ['Area_Code','Locality_Code','Region_Code','Species']\n",
        "mca                                = prince.MCA(n_components=1,random_state=202020).fit(concat_df[cat_cols])\n",
        "train_data.loc[:,'mca_cat1']        = mca.transform(train_data[cat_cols])[0]\n",
        "test_data.loc[:,'mca_cat1']         = mca.transform(test_data[cat_cols])[0]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y4nyKrSQ864",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cols                           = ['Height','Diameter']\n",
        "pca                                = PCA(n_components=1,random_state=202020).fit(concat_df[num_cols])\n",
        "train_data.loc[:,'pca_num']        = pca.transform(train_data[num_cols])[:,0]\n",
        "test_data.loc[:,'pca_num']         = pca.transform(test_data[num_cols])[:,0]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfSVlmXhQ89T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del concat_df\n",
        "concat_df                          = pd.concat((train_data,test_data),axis=0)\n",
        "concat_df['EFB1']                  = concat_df['Locality_Code'].astype(str)+'_'+concat_df['Species'].astype(str)\n",
        "concat_df['EFB2']                  = concat_df['Locality_Code'].astype(str)+'_'+concat_df['Region_Code'].astype(str)\n",
        "concat_df['EFB3']                  = concat_df['Species'].astype(str)+'_'+concat_df['Region_Code'].astype(str)\n",
        "concat_df['EFB4']                  = concat_df['Area_Code'].astype(str)+'_'+concat_df['Region_Code'].astype(str)\n",
        "concat_df['EFB5']                  = concat_df['Area_Code'].astype(str)+'_'+concat_df['Locality_Code'].astype(str)\n",
        "concat_df['EFB6']                  = concat_df['Area_Code'].astype(str)+'_'+concat_df['Species'].astype(str)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8W3O2P3Q9Au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9ebe275-c518-4ee8-9afb-93cd2530024a"
      },
      "source": [
        "concat_df['ratio_height_diam']     = np.where(concat_df['Diameter']!=0,concat_df['Height']/concat_df['Diameter'],np.NAN)\n",
        "aggregation_columns                = ['Height','Diameter','mca_cat1','pca_num','ratio_height_diam']\n",
        "numerical_aggregation_primary_keys = ['Area_Code','Locality_Code','Region_Code','Species']\n",
        "\n",
        "for cols in numerical_aggregation_primary_keys:\n",
        "    print(cols)\n",
        "    concat_df                       = updated_df(concat_df,cols,'mean',aggregation_columns)\n",
        "    concat_df                       = updated_df(concat_df,cols,'std',aggregation_columns)\n",
        "    concat_df                       = updated_df(concat_df,cols,'min',aggregation_columns)\n",
        "    concat_df                       = updated_df(concat_df,cols,'max',aggregation_columns)\n",
        "    concat_df                       = updated_df(concat_df,cols,'median',aggregation_columns)\n",
        "    print('\\n')\n",
        "\n",
        "concat_df                          = updated_df(concat_df,'Area_Code','nunique',['Species'])\n",
        "concat_df                          = updated_df(concat_df,'Locality_Code','nunique',['Species'])\n",
        "concat_df                          = updated_df(concat_df,'Region_Code','nunique',['Species'])\n",
        "\n",
        "concat_df                          = updated_df(concat_df,'Area_Code','nunique',['Locality_Code'])\n",
        "concat_df                          = updated_df(concat_df,'Region_Code','nunique',['Locality_Code'])\n",
        "concat_df                          = updated_df(concat_df,'Species','nunique',['Locality_Code'])\n",
        "\n",
        "concat_df                          = updated_df(concat_df,'Area_Code','nunique',['Region_Code'])\n",
        "concat_df                          = updated_df(concat_df,'Locality_Code','nunique',['Region_Code'])\n",
        "concat_df                          = updated_df(concat_df,'Species','nunique',['Region_Code'])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area_Code\n",
            "Aggregate  mean  on column-  Height\n",
            "Aggregate  mean  on column-  Diameter\n",
            "Aggregate  mean  on column-  mca_cat1\n",
            "Aggregate  mean  on column-  pca_num\n",
            "Aggregate  mean  on column-  ratio_height_diam\n",
            "Aggregate  std  on column-  Height\n",
            "Aggregate  std  on column-  Diameter\n",
            "Aggregate  std  on column-  mca_cat1\n",
            "Aggregate  std  on column-  pca_num\n",
            "Aggregate  std  on column-  ratio_height_diam\n",
            "Aggregate  min  on column-  Height\n",
            "Aggregate  min  on column-  Diameter\n",
            "Aggregate  min  on column-  mca_cat1\n",
            "Aggregate  min  on column-  pca_num\n",
            "Aggregate  min  on column-  ratio_height_diam\n",
            "Aggregate  max  on column-  Height\n",
            "Aggregate  max  on column-  Diameter\n",
            "Aggregate  max  on column-  mca_cat1\n",
            "Aggregate  max  on column-  pca_num\n",
            "Aggregate  max  on column-  ratio_height_diam\n",
            "Aggregate  median  on column-  Height\n",
            "Aggregate  median  on column-  Diameter\n",
            "Aggregate  median  on column-  mca_cat1\n",
            "Aggregate  median  on column-  pca_num\n",
            "Aggregate  median  on column-  ratio_height_diam\n",
            "\n",
            "\n",
            "Locality_Code\n",
            "Aggregate  mean  on column-  Height\n",
            "Aggregate  mean  on column-  Diameter\n",
            "Aggregate  mean  on column-  mca_cat1\n",
            "Aggregate  mean  on column-  pca_num\n",
            "Aggregate  mean  on column-  ratio_height_diam\n",
            "Aggregate  std  on column-  Height\n",
            "Aggregate  std  on column-  Diameter\n",
            "Aggregate  std  on column-  mca_cat1\n",
            "Aggregate  std  on column-  pca_num\n",
            "Aggregate  std  on column-  ratio_height_diam\n",
            "Aggregate  min  on column-  Height\n",
            "Aggregate  min  on column-  Diameter\n",
            "Aggregate  min  on column-  mca_cat1\n",
            "Aggregate  min  on column-  pca_num\n",
            "Aggregate  min  on column-  ratio_height_diam\n",
            "Aggregate  max  on column-  Height\n",
            "Aggregate  max  on column-  Diameter\n",
            "Aggregate  max  on column-  mca_cat1\n",
            "Aggregate  max  on column-  pca_num\n",
            "Aggregate  max  on column-  ratio_height_diam\n",
            "Aggregate  median  on column-  Height\n",
            "Aggregate  median  on column-  Diameter\n",
            "Aggregate  median  on column-  mca_cat1\n",
            "Aggregate  median  on column-  pca_num\n",
            "Aggregate  median  on column-  ratio_height_diam\n",
            "\n",
            "\n",
            "Region_Code\n",
            "Aggregate  mean  on column-  Height\n",
            "Aggregate  mean  on column-  Diameter\n",
            "Aggregate  mean  on column-  mca_cat1\n",
            "Aggregate  mean  on column-  pca_num\n",
            "Aggregate  mean  on column-  ratio_height_diam\n",
            "Aggregate  std  on column-  Height\n",
            "Aggregate  std  on column-  Diameter\n",
            "Aggregate  std  on column-  mca_cat1\n",
            "Aggregate  std  on column-  pca_num\n",
            "Aggregate  std  on column-  ratio_height_diam\n",
            "Aggregate  min  on column-  Height\n",
            "Aggregate  min  on column-  Diameter\n",
            "Aggregate  min  on column-  mca_cat1\n",
            "Aggregate  min  on column-  pca_num\n",
            "Aggregate  min  on column-  ratio_height_diam\n",
            "Aggregate  max  on column-  Height\n",
            "Aggregate  max  on column-  Diameter\n",
            "Aggregate  max  on column-  mca_cat1\n",
            "Aggregate  max  on column-  pca_num\n",
            "Aggregate  max  on column-  ratio_height_diam\n",
            "Aggregate  median  on column-  Height\n",
            "Aggregate  median  on column-  Diameter\n",
            "Aggregate  median  on column-  mca_cat1\n",
            "Aggregate  median  on column-  pca_num\n",
            "Aggregate  median  on column-  ratio_height_diam\n",
            "\n",
            "\n",
            "Species\n",
            "Aggregate  mean  on column-  Height\n",
            "Aggregate  mean  on column-  Diameter\n",
            "Aggregate  mean  on column-  mca_cat1\n",
            "Aggregate  mean  on column-  pca_num\n",
            "Aggregate  mean  on column-  ratio_height_diam\n",
            "Aggregate  std  on column-  Height\n",
            "Aggregate  std  on column-  Diameter\n",
            "Aggregate  std  on column-  mca_cat1\n",
            "Aggregate  std  on column-  pca_num\n",
            "Aggregate  std  on column-  ratio_height_diam\n",
            "Aggregate  min  on column-  Height\n",
            "Aggregate  min  on column-  Diameter\n",
            "Aggregate  min  on column-  mca_cat1\n",
            "Aggregate  min  on column-  pca_num\n",
            "Aggregate  min  on column-  ratio_height_diam\n",
            "Aggregate  max  on column-  Height\n",
            "Aggregate  max  on column-  Diameter\n",
            "Aggregate  max  on column-  mca_cat1\n",
            "Aggregate  max  on column-  pca_num\n",
            "Aggregate  max  on column-  ratio_height_diam\n",
            "Aggregate  median  on column-  Height\n",
            "Aggregate  median  on column-  Diameter\n",
            "Aggregate  median  on column-  mca_cat1\n",
            "Aggregate  median  on column-  pca_num\n",
            "Aggregate  median  on column-  ratio_height_diam\n",
            "\n",
            "\n",
            "Aggregate  nunique  on column-  Species\n",
            "Aggregate  nunique  on column-  Species\n",
            "Aggregate  nunique  on column-  Species\n",
            "Aggregate  nunique  on column-  Locality_Code\n",
            "Aggregate  nunique  on column-  Locality_Code\n",
            "Aggregate  nunique  on column-  Locality_Code\n",
            "Aggregate  nunique  on column-  Region_Code\n",
            "Aggregate  nunique  on column-  Region_Code\n",
            "Aggregate  nunique  on column-  Region_Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ8DqlhhQ9Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "943df097-162e-42b9-fcf9-add15c4b1b4c"
      },
      "source": [
        "testcount                          = len(test_data)\n",
        "count                              = len(concat_df)-testcount\n",
        "\n",
        "train_data                         = concat_df[:count]\n",
        "test_data                          = concat_df[count:]\n",
        "\n",
        "##### We identify categorical columns here\n",
        "cat_cols                           = ['Area_Code','Locality_Code','Region_Code','Species','EFB1','EFB2','EFB3','EFB4','EFB5','EFB6']\n",
        "for cols in cat_cols:\n",
        "    train_data[cols]               = train_data[cols].astype(str)\n",
        "    test_data[cols]                = test_data[cols].astype(str)\n",
        "    \n",
        "train                              = train_data.values\n",
        "test                               = test_data.values\n",
        "cate_features_index                = np.where(train_data.dtypes == object)[0]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFX6fEsLQ9ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0526feb-7542-404c-82fa-20f6febda829"
      },
      "source": [
        "oof_pred               = np.zeros((len(train),8))\n",
        "y_pred_final           = np.zeros((len(test), 8))\n",
        "num_models             = 2\n",
        "\n",
        "n_splits               = 44\n",
        "error                  = []\n",
        "kf                     = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (tr_ind, val_ind) in enumerate(kf.split(train, train_y)):\n",
        "    wghts              = [0]*num_models\n",
        "    logloss            = []\n",
        "    \n",
        "    X_train, X_val     = train[tr_ind], train[val_ind]\n",
        "    y_train, y_val     = train_y[tr_ind], train_y[val_ind]\n",
        "    \n",
        "    \n",
        "    \n",
        "    model1             = CatBoostClassifier(n_estimators=1200,random_state=202020,verbose=False,task_type='GPU')\n",
        "    model1.fit(X_train,y_train,cat_features = cate_features_index,eval_set=(X_val,y_val))\n",
        "    val_pred1          = model1.predict_proba(X_val)\n",
        "    logloss.append(log_loss(y_val,val_pred1))\n",
        "    print('validation logloss model 1 fold-',fold+1,': ',log_loss(y_val,val_pred1))\n",
        "    \n",
        "    \n",
        "    model2             = CatBoostClassifier(n_estimators=1000,random_state=202020,verbose=False,task_type='GPU')\n",
        "    model2.fit(X_train,y_train,cat_features = cate_features_index,eval_set=(X_val,y_val))\n",
        "    val_pred2          = model2.predict_proba(X_val)\n",
        "    logloss.append(log_loss(y_val,val_pred2))\n",
        "    print('validation logloss model 2 fold-',fold+1,': ',log_loss(y_val,val_pred2))\n",
        "    \n",
        "    \n",
        "    wghts              = np.exp(-1000*np.array(logloss/sum(logloss)))\n",
        "    wghts              = wghts/sum(wghts)\n",
        "    \n",
        "    val_pred           = wghts[0]*val_pred1+wghts[1]*val_pred2\n",
        "    print('validation logloss fold-',fold+1,': ',log_loss(y_val, val_pred))\n",
        "    \n",
        "    oof_pred[val_ind]  = val_pred\n",
        "    \n",
        "    y_pred_final += (wghts[0]*model1.predict_proba(test)+wghts[1]*model2.predict_proba(test))/(n_splits)\n",
        "    \n",
        "    print('\\n')\n",
        "    \n",
        "print('OOF logloss:- ',(log_loss(train_y,oof_pred)))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation logloss model 1 fold- 1 :  0.7871682752555085\n",
            "validation logloss model 2 fold- 1 :  0.7702258510455616\n",
            "validation logloss fold- 1 :  0.7702258524887252\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 2 :  0.7154910619170367\n",
            "validation logloss model 2 fold- 2 :  0.7267564598881723\n",
            "validation logloss fold- 2 :  0.7154860908582914\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 3 :  0.6446262604111138\n",
            "validation logloss model 2 fold- 3 :  0.6384315934852578\n",
            "validation logloss fold- 3 :  0.6383101127168538\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 4 :  0.6969632414941853\n",
            "validation logloss model 2 fold- 4 :  0.6975267473643445\n",
            "validation logloss fold- 4 :  0.6905018915495782\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 5 :  0.7248437692521489\n",
            "validation logloss model 2 fold- 5 :  0.7424126026651026\n",
            "validation logloss fold- 5 :  0.7248437145819717\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 6 :  0.717518705854868\n",
            "validation logloss model 2 fold- 6 :  0.735519046641254\n",
            "validation logloss fold- 6 :  0.7175186752378697\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 7 :  0.6483179702353048\n",
            "validation logloss model 2 fold- 7 :  0.6388591404835399\n",
            "validation logloss fold- 7 :  0.6388482541375731\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 8 :  0.6814139634254374\n",
            "validation logloss model 2 fold- 8 :  0.7101377746591206\n",
            "validation logloss fold- 8 :  0.6814139634337941\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 9 :  0.7335234435922691\n",
            "validation logloss model 2 fold- 9 :  0.733434677233351\n",
            "validation logloss fold- 9 :  0.7296542819516202\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 10 :  0.664359439871379\n",
            "validation logloss model 2 fold- 10 :  0.6688277329876947\n",
            "validation logloss fold- 10 :  0.6627646236493748\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 11 :  0.7396437275354101\n",
            "validation logloss model 2 fold- 11 :  0.7581270578396142\n",
            "validation logloss fold- 11 :  0.7396436904704898\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 12 :  0.6809572824567793\n",
            "validation logloss model 2 fold- 12 :  0.6717450626806389\n",
            "validation logloss fold- 12 :  0.671730188966552\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 13 :  0.6816328733023234\n",
            "validation logloss model 2 fold- 13 :  0.6894045388705302\n",
            "validation logloss fold- 13 :  0.6815335804219382\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 14 :  0.8105974489132923\n",
            "validation logloss model 2 fold- 14 :  0.816086007984752\n",
            "validation logloss fold- 14 :  0.8096493477652975\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 15 :  0.7406420088579403\n",
            "validation logloss model 2 fold- 15 :  0.7463433404603285\n",
            "validation logloss fold- 15 :  0.7402744718921928\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 16 :  0.7013468543364603\n",
            "validation logloss model 2 fold- 16 :  0.6970550849588901\n",
            "validation logloss fold- 16 :  0.6957074469242355\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 17 :  0.7904187877247769\n",
            "validation logloss model 2 fold- 17 :  0.7743572877186872\n",
            "validation logloss fold- 17 :  0.7743571463150956\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 18 :  0.7475312365019404\n",
            "validation logloss model 2 fold- 18 :  0.7531069458983125\n",
            "validation logloss fold- 18 :  0.7468957293368549\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 19 :  0.6992939204880831\n",
            "validation logloss model 2 fold- 19 :  0.7125019006362879\n",
            "validation logloss fold- 19 :  0.6992929726455057\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 20 :  0.6614063842608414\n",
            "validation logloss model 2 fold- 20 :  0.6530292994250068\n",
            "validation logloss fold- 20 :  0.6529869422281478\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 21 :  0.6986643771050711\n",
            "validation logloss model 2 fold- 21 :  0.6859500620931984\n",
            "validation logloss fold- 21 :  0.6859483380555257\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 22 :  0.7188910625013657\n",
            "validation logloss model 2 fold- 22 :  0.7103536748214765\n",
            "validation logloss fold- 22 :  0.710309370769378\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 23 :  0.7643593616181511\n",
            "validation logloss model 2 fold- 23 :  0.7624017814195498\n",
            "validation logloss fold- 23 :  0.7595083570846239\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 24 :  0.6669380563110814\n",
            "validation logloss model 2 fold- 24 :  0.6572880278834093\n",
            "validation logloss fold- 24 :  0.6572728147204453\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 25 :  0.8191168387255015\n",
            "validation logloss model 2 fold- 25 :  0.8253004505597028\n",
            "validation logloss fold- 25 :  0.8189162606997206\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 26 :  0.6973007845028236\n",
            "validation logloss model 2 fold- 26 :  0.6969008224591525\n",
            "validation logloss fold- 26 :  0.6894929701821886\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 27 :  0.717899356776734\n",
            "validation logloss model 2 fold- 27 :  0.7092328492053471\n",
            "validation logloss fold- 27 :  0.7091471345374144\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 28 :  0.8072498061440816\n",
            "validation logloss model 2 fold- 28 :  0.827500797087767\n",
            "validation logloss fold- 28 :  0.8072497602307548\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 29 :  0.7609152556540821\n",
            "validation logloss model 2 fold- 29 :  0.776695839497723\n",
            "validation logloss fold- 29 :  0.7609149788647904\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 30 :  0.693180020766071\n",
            "validation logloss model 2 fold- 30 :  0.6953393444035932\n",
            "validation logloss fold- 30 :  0.6904054247987573\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 31 :  0.6999890290507498\n",
            "validation logloss model 2 fold- 31 :  0.6934211180150665\n",
            "validation logloss fold- 31 :  0.6932818037025421\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 32 :  0.7629815014741801\n",
            "validation logloss model 2 fold- 32 :  0.7587698286766119\n",
            "validation logloss fold- 32 :  0.7580975187387333\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 33 :  0.7782304730863107\n",
            "validation logloss model 2 fold- 33 :  0.767934078301873\n",
            "validation logloss fold- 33 :  0.7679104472208731\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 34 :  0.6330619601064276\n",
            "validation logloss model 2 fold- 34 :  0.6350960019378196\n",
            "validation logloss fold- 34 :  0.6293821391004382\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 35 :  0.7315470754388446\n",
            "validation logloss model 2 fold- 35 :  0.7309611699627729\n",
            "validation logloss fold- 35 :  0.7256328353754957\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 36 :  0.7032598905896152\n",
            "validation logloss model 2 fold- 36 :  0.6969019041833449\n",
            "validation logloss fold- 36 :  0.6968070332611997\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 37 :  0.6389191877470177\n",
            "validation logloss model 2 fold- 37 :  0.6355225252325215\n",
            "validation logloss fold- 37 :  0.6336673089283357\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 38 :  0.7523270880316043\n",
            "validation logloss model 2 fold- 38 :  0.7557252399794638\n",
            "validation logloss fold- 38 :  0.7505122748347787\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 39 :  0.7465977923734282\n",
            "validation logloss model 2 fold- 39 :  0.7551100604681243\n",
            "validation logloss fold- 39 :  0.7465458031334752\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 40 :  0.7370330058613678\n",
            "validation logloss model 2 fold- 40 :  0.7449253677920776\n",
            "validation logloss fold- 40 :  0.7369121859907285\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 41 :  0.7925932315214325\n",
            "validation logloss model 2 fold- 41 :  0.7889991648085463\n",
            "validation logloss fold- 41 :  0.7872172288899111\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 42 :  0.667554514387022\n",
            "validation logloss model 2 fold- 42 :  0.6712518301555545\n",
            "validation logloss fold- 42 :  0.6665447703157532\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 43 :  0.6471422879213674\n",
            "validation logloss model 2 fold- 43 :  0.6534758104601451\n",
            "validation logloss fold- 43 :  0.6469865471792156\n",
            "\n",
            "\n",
            "validation logloss model 1 fold- 44 :  0.7610680490451952\n",
            "validation logloss model 2 fold- 44 :  0.7633752037346617\n",
            "validation logloss fold- 44 :  0.758086053350683\n",
            "\n",
            "\n",
            "OOF logloss:-  0.7151866057651985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-17DcJtBQ8xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkR5CUIBQ8p8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTepNtpMQ8di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}